<h1 align="center">
  GRUPO 10 - Ponele M√∫sica a Tus Emociones - ISPC
</h1>

<p align="center">
  <img src="https://github.com/ClaudiaMetz/ISPC---PP1---Grupo-10/blob/main/CD.png" width="100%" title="Intro Card" alt="Intro Card">
</p>
<h2 align="center">Integrantes: üë©üèæ‚Äçüíª </h2>
<h5 align="center">Hilgemberg Maria Sol<br>
<b>Soria Julio Ezequiel</b><br>
<b>Bustos Jonathan</b><br>
<b>Metz Claudia</b><br>
<b>Quiroga Horacio Eduardo</b><br>
<b>Meier Ivan Didier</b><br>
<b>Mu√±oz Mariel</b><br></h5>

---




# Ponele M√∫sica a Tus Emociones-Grupo10-ISPC-TSCDIA

---

<b>Idea Principal:</b> Detectar la Emoci√≥n en una foto y Recomendar una Canci√≥n
<br>
<p><b>Este trabajo combina t√©cnicas de Procesamiento de Im√°genes y Machine Learning para crear una experiencia √∫nica: El usuario suministra una fotograf√≠a por medio de la computadora, luego la aplicaci√≥n web analiza la emoci√≥n predominante en la foto utilizando un modelo de Aprendizaje Profundo. Luego se selecciona una canci√≥n de una base de datos o conjunto de temas musicales y la expresa con un audio. <br>
Para su desarrollo utilizamos t√©cnicas de Miner√≠a de Datos y Aprendizaje Autom√°tico. <br>
Se utiliz√≥ el dataset FER2013 [Dataset üåü](https://drive.google.com/file/d/1vtWxb5LioAATFb5Qypqa0zavj4NPoj06/view?usp=drive_link). (Facial Expression Recognition 2013) contiene im√°genes junto con categor√≠as que describen la emoci√≥n de la persona en ellas. <br>

Este proyecto busca aprovechar el deep learning y el procesamiento de im√°genes para las personas puedan revivir momentos especiales o simplemente para explorar nuevas sensaciones. Y en cada nota, en cada imagen, encontrar√°n un eco de su propia historia.
<b><br></p>
<p align="center">
  <img src="[https://github.com/ClaudiaMetz/ISPC---PP1---Grupo-10/blob/main/CD.png](https://drive.google.com/file/d/1GFpOeiYm3X5lxhz8wbGrPh-VdwFfp-mK/view?usp=drive_link)" width="100%" title="Historia" alt="Historia">
</p>

---

# Objetivo General
Desarrollar un sistema automatizado basado en deep learning para detectar emociones mediante fotograf√≠as que el usuario suministre, con el fin de obtener una canci√≥n que refleje el resultado obtenido.

# Objetivos Espec√≠ficos
Recolecci√≥n y Preparaci√≥n de Datos
o Obtener un Dataset, que se adapte al campo del reconocimiento de expresiones faciales.
FER2013 [Dataset üåü](https://drive.google.com/file/d/1vtWxb5LioAATFb5Qypqa0zavj4NPoj06/view?usp=drive_link)

o Corroborar una muestra del conjunto de im√°genes con las etiquetas para crear un conjunto de datos de entrenamiento consistente.

Desarrollo del Modelo de Deep Learning

o Dise√±ar y entrenar un modelo de aprendizaje profundo que pueda identificar emociones, bas√°ndose en caracter√≠sticas visuales de los rostros.

o Evaluar el rendimiento del modelo por medio de metr√≠cas adecuadas y realizar ajustes necesarios para optimizar su desempe√±o.

Implementaci√≥n del Sistema de Detecci√≥n

o Implementar una p√°gina web donde los usuarios puedan cargas sus fotos y la aplicaci√≥n detecte la emoci√≥n y se obtenga la canci√≥n.

Validaci√≥n y Verificaci√≥n
o Realizar pruebas y validaci√≥n para asegurar la precisi√≥n y robustez del sistema.

o Ajustar el modelo y el sistema en base a los resultados obtenidos para mejorar su confiabilidad y precisi√≥n.

Metodolog√≠a
An√°lisis de Requisitos:
o Definir claramente los requisitos t√©cnicos y funcionales del sistema.

o Establecer los criterios de √©xito y las m√©tricas de evaluaci√≥n.

Desarrollo Iterativo:
o Seguir un enfoque √°gil para el desarrollo del sistema, permitiendo iteraciones r√°pidas y ajustes continuos basados en retroalimentaci√≥n.

Colaboraci√≥n y Feedback:
o Mantener una comunicaci√≥n constante con los usuarios de la aplicaci√≥n para asegurar que el sistema desarrollado satisfaga sus necesidades.

Monitoreo y Mejora Continua:
o Implementar un sistema de monitoreo para evaluar continuamente el rendimiento del sistema en producci√≥n.

o Planificar actualizaciones y mejoras basadas en nuevos datos y nuevas tecnolog√≠as.

<p align="center">
  <img src="[https://github.com/ClaudiaMetz/ISPC---PP1---Grupo-10/blob/main/CD.png](https://drive.google.com/file/d/1GFpOeiYm3X5lxhz8wbGrPh-VdwFfp-mK/view?usp=drive_link)" width="100%" title="CRISP" alt="CRISP">
</p>
---

Modelo de Referencia CRISP-DM
1. Comprensi√≥n del Negocio
Objetivos y requisitos del Proyecto, definici√≥n del problema y plan preliminar dise√±ado.

üìå Desarrollar un sistema automatizado que use:

 Fotograf√≠as que el usuario cargue

 Algoritmos de aprendizaje profundo, entrenados para reconocer rasgos faciales y detectar emociones.

üìå Objetivo del sistema automatizado

El objetivo es que la aplicaci√≥n pueda identificar emociones a trav√©s de los rostros de im√°genes cargadas. √âste sistema podr√≠a ayudar a detectar cambios de √°nimo y emociones que presenta una im√°gen o persona.

üìå Definici√≥n del Problema y Plan Preliminar Dise√±ado

El problema a resolver es el reconocimiento facial automatizado en im√°genes para luego buscar una frase que permita obtener una canci√≥n relacionada con la emoci√≥n detectada. Para abordar este problema, se propone un procedimiento completo de aprendizaje profundo que incluye:

Lectura de datos

Se obtendr√°n im√°genes de un dataset previamente descargado, que ser√°n utilizadas como base de datos principal.
Utilizaremos el dataset FER2013, un recurso muy utilizado en el campo del reconocimiento de expresiones faciales y que puede proporcionarnos una buena variedad de datos para entrenar un modelo, asegurando que la informaci√≥n sea correctamente procesada y preparada para el entrenamiento del modelo.

Entrenamiento de modelos

Se entrenan modelos de aprendizaje profundo, espec√≠ficamente redes neuronales convolucionales(CNN), para reconocer las caracter√≠sticas distintivas de los rostros de las personas en las im√°genes.

El entrenamiento del modelo 

Realizaci√≥n de predicciones

Una vez que el modelo est√© entrenado , se ingresar√°n nuevas im√°genes de rostros para identificar las emociones.
Las predicciones ser√°n validadas y ajustadas para mejorar la precisi√≥n del sistema. Esto incluye la evaluaci√≥n del rendimiento del modelo utilizando m√©tricas como la precisi√≥n , el recall y el F1-score, y realizando ajustes basados en los resultados de estas evaluaciones.


üìå Desarrollo del Sistema Automatizado

Fotograf√≠as provistas por el usuario
El sistema utiliza im√°genes con rostros para identificar las emociones. La calidad y resoluci√≥n de estas im√°genes son esenciales para la precisi√≥n modelo. 

Algoritmo de Aprendizaje Profundo
Se entrenan algoritmos de aprendizaje profundo, espec√≠ficamente dise√±ados para recorrer formas en las im√°genes. El entrenamiento incluir√° t√©cnicas de argumentaci√≥n de datos para mejorar la robustez del modelo......

üìå Identificaci√≥n de las partes interesadas y sus necesidades

Partes interesadas:

Equipo de desarrollo del proyecto: Incluye a Claudia Metz y Jonathan Bustos, quienes est√°n a cargo de desarrollar y entrenar el modelo de deep learning.

Usuarios finales: Cualquier persona o empresa que est√©n interesadas en contar con una aplicaci√≥n que convine IA y M√∫sica.

Necesidades:

Automatizaci√≥n y precisi√≥n: Desarrollar un sistema automatizado que utilice im√°genes de rostros y algoritmos de aprendizaje profundo para identificar las emociones.

Visualizaci√≥n y evaluaci√≥n: Capacidad para visualizar los resultados de la segmentaci√≥n sem√°ntica y evaluar la precisi√≥n del modelo.

2. Comprensi√≥n de los Datos
Recopilaci√≥n , primeros conocimientos de los datos
El primer paso en la fase de comprensi√≥n de los datos del modelo CRISP-DM implica la identificaci√≥n y adquisici√≥n de las fuentes de datos relevantes. Este proceso es fundamental para asegurar que se cuenta con la informaci√≥n adecuada para abordar el problema planteado.

1. Identificaci√≥n de Fuentes de Datos:
Dataset: Para este proyecto, las im√°genes fueron obtenidad desde Keagle.com, del dataset FER2013 (Facial Expression Recognition 2013).
Fotograf√≠as: Fotograf√≠as que el usuario cargue en la aplicaci√≥n.

2. An√°lisis Exploratorios de las Im√°genes:
Visualizaci√≥n de Im√°genes: Se realiza una visualizaci√≥n inicial de las im√°genes para comprender mejor su contenido y caracter√≠sticas visuales.
Resoluci√≥n y Metadatos: Es esencial entender la resoluci√≥n espacial de las im√°genes, que determina el nivel de detalle que se puede observar. Adem√°s, se revisan los metadatos para obtener informaci√≥n adicional.

Instalaci√≥n de Librer√≠as y Configuraci√≥n del Entorno
A continuaci√≥n se observa las importaciones de bibliotecas de Python que son √∫tiles para procesamiento de im√°genes, visualizaci√≥n de datos, y construcci√≥n de modelos de aprendizaje autom√°tico y profundo:
NumPy (import numpy as np): Biblioteca fundamental para computaci√≥n cient√≠fica en Python. Proporciona soporte para grandes matrices multidimensionales y una colecci√≥n de funciones matem√°ticas de alto nivel.
SciPy (from scipy import misc): Biblioteca que complementa a NumPy y proporciona funciones adicionales para computaci√≥n cient√≠fica. Aqu√≠ se importa el subm√≥dulo misc, que contiene funciones de utilidad miscel√°neas.
PIL (Python Imaging Library) (from PIL import Image): Biblioteca para la manipulaci√≥n de im√°genes.
glob (import glob): Biblioteca para encontrar todos los nombres de ruta que coinciden con un patr√≥n especificado, √∫til para manejar m√∫ltiples archivos.
Matplotlib (import matplotlib.pyplot as plt y from matplotlib.pyplot import imshow): Biblioteca para crear gr√°ficos y visualizaciones.
IPython.display (from IPython.display import SVG): Biblioteca para mostrar contenido interactivo en Jupyter Notebooks.
OpenCV (import cv2): Biblioteca de visi√≥n por computadora para procesar im√°genes y videos.
Seaborn (import seaborn as sn): Biblioteca para visualizaci√≥n de datos basada en Matplotlib, proporciona una interfaz de alto nivel para dibujar gr√°ficos estad√≠sticos atractivos y informativos.
Pandas (import pandas as pd): Biblioteca para manipulaci√≥n y an√°lisis de datos, proporciona estructuras de datos flexibles y eficientes.
pickle (import pickle): Biblioteca para serializar y deserializar estructuras de objetos de Python.
Keras (import keras y varios subm√≥dulos): Biblioteca de alto nivel para crear y entrenar modelos de aprendizaje profundo. Las importaciones incluyen capas, modelos, optimizadores, funciones de p√©rdida, y utilidades para trabajar con datos de im√°genes.
TensorFlow (import tensorflow as tf y subm√≥dulos de Keras dentro de TensorFlow): Plataforma de aprendizaje autom√°tico de extremo a extremo. Aqu√≠ se importa para usar junto con Keras, ya que Keras es una API de alto nivel que puede funcionar sobre TensorFlow.
Scikit-learn (from sklearn.metrics import confusion_matrix, classification_report): Biblioteca para aprendizaje autom√°tico en Python. Aqu√≠ se importa para evaluar modelos con matrices de confusi√≥n y reportes de clasificaci√≥n.
ImageDataGenerator (from tensorflow.keras.preprocessing.image import ImageDataGenerator): Utilidad de Keras para generar nuevas im√°genes mediante t√©cnicas de aumento de datos.
VGG (from keras.applications import vgg16, vgg19): Modelos de redes neuronales convolucionales preentrenados, √∫tiles para tareas de clasificaci√≥n de im√°genes y transferencia de aprendizaje.

Estas importaciones proporcionan un conjunto robusto de herramientas para el procesamiento y an√°lisis de im√°genes, construcci√≥n y entrenamiento de modelos de aprendizaje profundo, y evaluaci√≥n del rendimiento de los modelos en Python.

Cargar en Google Drive: El dataset se carg√≥ en Google Drive para permitir un f√°cil acceso y manipulaci√≥n desde cualquier lugar.

An√°lisis exploratorio de los datos

Como se puede apreciar el dataset consiste de 3 columnas:
emotion: Contiene la etiqueta que define la emoci√≥n de la im√°gen y es nuestra variable objetivo. (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)
pixels: Corresponden a los valores de cada uno de los pixeles. De acuerdo con las instrucciones de la competencia, las im√°genes son de 48x48.
Usage: Corresponde al set de datos correspondientes: Train, PublicTest, Private Test.

Se puede ver que existen cerca de 28700 im√°genes que son utilizadas para entrenamiento. Estas im√°genes contienen una etiqueta por lo que pod√≠an ser utilizadas para entrenar.

Adicionalmente se pueden ver dos grupos, Public y Private Test que correspond√≠an a los Sets de Validaci√≥n. El set p√∫blico era el que se usaba para evaluar los resultados al subirlos a la plataforma, mientras que el Private correspond√≠a a los datos ocultos que se liberan s√≥lo al finalizar la competencia para decidir a los ganadores.


## Caracter√≠sticas del Proyecto

Objetivo: Utilizar el procesamiento de im√°genes y machine learning para detectar emociones en rostros de personas.
 
Calidad y Configuraci√≥n de Datos
Dataset: FER2013 (Facial Expression Recognition 2013 - kaggle.com)
Preprocesamiento: Esta etapa incluy√≥ la normalizaci√≥n de las im√°genes, conversi√≥n de etiquetas a categ√≥ricas.

Calidad del C√≥digo
Estructura: El c√≥digo est√° bien organizado, con comentarios explicativos y secciones claramente definidas.
Modelo de Deep Learning: Utilizamos un modelo DenseNet121, el cual introduce conexiones directas entre todas las capas. Su principal ventaja es la capacidad de determinar caracter√≠sticas y patrones m√°s discriminativas gracias a su mayor flujo de informaci√≥n. Adem√°s, el modelo reduce el problema de desvanecimiento del gradiente. 
Sin embargo, la profundidad del modelo, con el n√∫mero de capas que conlleva, y las conexiones entre ellas hace de este modelo muy pesado computacionalmente a la hora de su entrenamiento.

3. Preparaci√≥n de los Datos
Seleccion de tablas, registros y atributos, transformaci√≥n y limpieza de datos.

Preparar los datos para el modelado implica la limpieza de las im√°genes, la evaluaci√≥n del dataset , la eliminaci√≥n de las partes no deseadas y la preparaci√≥n de las etiquetas para el entrenamiento del modelo, afortunadamente en el dataset utilizado, los datos ya se encontraban tabulados casi de la forma que los necesit√°bamos


üß™ Entrenamiento del modelo 'resnet18'

Carga del Modelo Preentrenado:

Se configura el modelo para el preprocesamiento de datos (conversi√≥n de im√°genes  de un canal a tres canales, convertir etiquetas a categ√≥ricas, deivir el dataset en entranamiento, validaci√≥n y prueba).
Se aplica t√©cnica de argumentaci√≥n de datos para mejorar la robustez del modelo.
Se definen las entradas del modelo.
Se redimensionan las entradas que coincidan con el modelo preentrenado
Se carga un modelo DenseNet121 utilizando tensorflow.keras.applications
Se agregan capas personalizadas: 
    o	GlobalAveragePooling2D: Reduce las dimensiones espaciales del tensor (de (7, 7, ...) a (1, 1, ...)).
    o	Capas densas (Dense):
    ÔÇß	1024, 512 y 256 neuronas con activaci√≥n ReLU.
    ÔÇß	BatchNormalization: Normaliza los valores para mejorar la estabilidad del entrenamiento.
    ÔÇß	Dropout(0.5): Reduce el sobreajuste al desactivar aleatoriamente el 50% de las neuronas.
    o	Capa final (Dense(7, activation="softmax")):
    ÔÇß	Produce una probabilidad para cada una de las 7 clases.

Entrenamiento del Modelo:

 Se inicia el entrenamiento del modelo con los conjuntos de datos preparados.
 Se realizan iteraciones (√©pocas) donde el modelo aprende a identificar caracter√≠sticas faciales y emociones.

üß™ Preprocesar y Transformar los datos para su uso en el modelo .................


4. Modelado
- [Ver modelo üåü](FotoEmocion__Cancion.ipynb)
Selecci√≥n y aplicaci√≥n de varias t√©cnicas de modelado

üìù Seleccionar el modelo de aprendizaje profundo (Densenet121)

Utilizamos un modelo DenseNet121, el cual introduce conexiones directas entre todas las capas. Su principal ventaja es la capacidad de determinar caracter√≠sticas y patrones m√°s discriminativas gracias a su mayor flujo de informaci√≥n. Adem√°s, el modelo reduce el problema de desvanecimiento del gradiente. 
Sin embargo, la profundidad del modelo, con el n√∫mero de capas que conlleva, y las conexiones entre ellas hace de este modelo muy pesado computacionalmente a la hora de su entrenamiento.


üìù Configurar el modelo y los par√°metros de entrenamiento

Configuraci√≥n de Par√°metros del Modelo: Los par√°metros del modelo, como el n√∫mero de capas y neuronas, as√≠ como las funciones de activaci√≥n, se configuran de acuerdo con las necesidades de la tarea.

Configuraci√≥n de Par√°metros de Entrenamiento: Los par√°metros de entrenamiento, como el n√∫mero de √©pocas, el tama√±o del lote y la tasa de aprendizaje, se establecen. Estos par√°metros pueden tener un gran impacto en la eficacia del entrenamiento.

üìù Entrenar el modelo con los datos de entrenamiento

El modelo se entrena utilizando los datos de entrenamiento, ajustando los pesos y los par√°metros internos de la red para minimizar el error.
Se inicia el entrenamiento del modelo con los conjuntos de datos preparados.
Se realizan iteraciones (epoch) donde el modelo aprende a expresiones faciales en las im√°genes.
Se configuran los callback y el data augmentation para:
   Optimizar el entrenamiento.
   Ahorrar tiempo y recursos.
   Mejorar la generalizaci√≥n.
   Evitar el sobreajuste.
 
En conjunto, los callbacks y el data augmentation sirven para mejorar la eficiencia y la calidad del entrenamiento de un modelo de aprendizaje profundo. Aqu√≠ est√° el prop√≥sito principal de cada uno:

Callbacks:
Optimizar el entrenamiento:

EarlyStopping previene el sobreajuste deteniendo el entrenamiento cuando el modelo deja de mejorar en los datos de validaci√≥n.
ReduceLROnPlateau ajusta autom√°ticamente el learning rate para permitir que el modelo refine su aprendizaje cuando el progreso se desacelera.
Ahorrar tiempo y recursos:

Detener el entrenamiento antes de completar todas las √©pocas evita desperdiciar tiempo en √©pocas improductivas.
Reducir el learning rate ayuda al modelo a converger m√°s eficientemente hacia una soluci√≥n √≥ptima.
Data Augmentation:
Mejorar la generalizaci√≥n:

Genera datos nuevos a partir de los existentes aplicando transformaciones aleatorias (como rotaciones, desplazamientos o cambios de brillo).
Esto aumenta la diversidad del conjunto de entrenamiento sin necesidad de recolectar m√°s datos.
Evitar el sobreajuste:

Al exponer al modelo a variaciones de los datos de entrenamiento, se hace menos probable que memorice ejemplos espec√≠ficos y m√°s probable que aprenda caracter√≠sticas generales.
Beneficio combinado:
Los callbacks garantizan un entrenamiento eficiente, ajustando din√°micamente el proceso seg√∫n el desempe√±o del modelo.
El data augmentation mejora la calidad del aprendizaje, ayudando al modelo a ser m√°s robusto y generalizable.
Ambos trabajan juntos para producir un modelo que no solo se entrena de manera eficiente, sino que tambi√©n funciona bien con datos nuevos (no vistos).

5. Evaluaci√≥n
Evaluaci√≥n del modelo y revisi√≥n de los pasos ejecutados La evaluaci√≥n del rendimiento del modelo permite comprender c√≥mo se comporta el modelo en datos no vistos durante el entrenamiento .Este an√°lisis se realiza utilizando el conjunto de datos de validaci√≥n y se mide mediante diversas m√©tricas de evaluaci√≥n como la precisi√≥n, la exhaustividad (recall), el puntaje F1 y el AUC-ROC.

üî¨ Prop√≥sitos de la Evaluaci√≥n Evaluar el rendimiento del modelo con los datos de validaci√≥n es crucial para varios prop√≥sitos:

Generalizaci√≥n: Evaluar c√≥mo el modelo se comporta en datos no vistos durante el entrenamiento. Los datos de validaci√≥n proporcionan una estimaci√≥n realista del rendimiento en situaciones del mundo real.
Ajustes de Hiperparametros: Durante la validaci√≥n, podemos ajustar los hiper par√°metros del modelo (como la tasa de aprendizaje, el tama√±o del lote, etc) para obtener un mejor rendimiento.
Selecci√≥n de Modelos: Comparamos diferentes modelos o arquitecturas utilizando los datos de validaci√≥n para elegir el mejor.
Evitar el sobreajuste: Si el modelo tiene un rendimiento excelente en los datos de entrenamiento, pero no en los de validaci√≥n, podr√≠a ser sobre ajustado. La validaci√≥n ayuda a detectar esto.
En resumen, la evaluaci√≥n con datos de validaci√≥n nos permite comprender como nuestro modelo se desempe√±ar√° en el mundo real y tomar decisiones informadas para mejorarlo.

-- Resultados de Evaluaci√≥n del Modelo
Despu√©s de ejecutar el c√≥digo para evaluar el modelo, obtuvimos los siguientes resultados:

Test Loss (P√©rdida en el conjunto de prueba): 0.920417308807373
Test Accuracy (Precisi√≥n en el conjunto de prueba): 0.6625185608863831

1. Test Loss (P√©rdida en el conjunto de prueba)

Valor: 0.920417308807373
La "p√©rdida" es una m√©trica que mide el error del modelo en el conjunto de datos de prueba. Un valor m√°s bajo de p√©rdida indica que el modelo est√° haciendo predicciones m√°s precisas. En este caso, una p√©rdida de aproximadamente 0.92 indica que el modelo tiene un error moderado al predecir las emociones en las im√°genes del conjunto de prueba. Sin embargo, este valor por s√≠ solo no proporciona una imagen completa del rendimiento del modelo, ya que depende del contexto y del valor de la funci√≥n de p√©rdida utilizada durante el entrenamiento.
2. Test Accuracy (Precisi√≥n en el conjunto de prueba)

Valor: 0.6625185608863831
La precisi√≥n es la proporci√≥n de predicciones correctas realizadas por el modelo en el conjunto de datos de prueba. En este caso, una precisi√≥n de aproximadamente 66.25% significa que el modelo predice correctamente las emociones en el 66.25% de las im√°genes de prueba.

--- INGRESAR GRAFICO

Los gr√°ficos muestran la evoluci√≥n de la precisi√≥n (accuracy) y la p√©rdida (loss) durante el entrenamiento y la validaci√≥n de un modelo de aprendizaje autom√°tico a lo largo de varias √©pocas.

Gr√°fico 1: Training Accuracy vs Validation Accuracy

‚Ä¢ Eje Y: Precisi√≥n (Accuracy). 
‚Ä¢ Eje X: N√∫mero de √©pocas (Num of Epochs). 
‚Ä¢ L√≠nea Roja: Precisi√≥n en el conjunto de entrenamiento (Train Accuracy). 
‚Ä¢ L√≠nea Verde: Precisi√≥n en el conjunto de validaci√≥n (Validation Accuracy).

Observaciones:
Precisi√≥n del entrenamiento (l√≠nea roja): Aumenta constantemente a medida que el modelo se entrena, alcanzando cerca del 90% hacia la √∫ltima √©poca.
Precisi√≥n de la validaci√≥n (l√≠nea verde): Aumenta inicialmente pero se estabiliza y fluct√∫a alrededor del 70% despu√©s de unas pocas √©pocas.

Interpretaci√≥n:
‚Ä¢ El modelo est√° aprendiendo bien en el conjunto de entrenamiento, lo que se refleja en el aumento constante de la precisi√≥n de entrenamiento. 
‚Ä¢ La precisi√≥n de validaci√≥n se estabiliza y no mejora mucho despu√©s de unas pocas √©pocas, lo cual sugiere que el modelo puede estar sobreajust√°ndose (overfitting) al conjunto de entrenamiento, ya que la brecha entre la precisi√≥n de entrenamiento y de validaci√≥n se ensancha con el tiempo.

Gr√°fico 2: Training Loss vs Validation Loss

‚Ä¢ Eje Y: P√©rdida (Loss). 
‚Ä¢ Eje X: N√∫mero de √©pocas (Num of Epochs). 
‚Ä¢ L√≠nea Roja: P√©rdida en el conjunto de entrenamiento (Train Loss). 
‚Ä¢ L√≠nea Verde: P√©rdida en el conjunto de validaci√≥n (Validation Loss).

Observaciones:

P√©rdida del entrenamiento (l√≠nea roja): Disminuye constantemente a medida que el modelo se entrena.
P√©rdida de la validaci√≥n (l√≠nea verde): Disminuye inicialmente pero luego se estabiliza e incluso muestra un ligero aumento hacia el final.

Interpretaci√≥n:

‚Ä¢ La disminuci√≥n continua de la p√©rdida de entrenamiento indica que el modelo est√° mejorando en su capacidad de predecir los datos de entrenamiento. 
‚Ä¢ La p√©rdida de validaci√≥n disminuye al principio, lo que sugiere que el modelo mejora, pero luego se estabiliza e incluso aumenta ligeramente, lo cual es una se√±al de sobreajuste. Esto significa que el modelo est√° memorizando los datos de entrenamiento en lugar de generalizar bien a datos nuevos.


Conclusi√≥n General
Los resultados y las observaciones de los gr√°ficos sugieren que el modelo est√° aprendiendo eficazmente del conjunto de entrenamiento, como lo indican la alta precisi√≥n de entrenamiento y la disminuci√≥n constante de la p√©rdida de entrenamiento. Sin embargo, la precisi√≥n de validaci√≥n que se estabiliza y la p√©rdida de validaci√≥n que aumenta ligeramente indican que el modelo no generaliza bien a datos nuevos, un signo claro de sobreajuste.

Recomendaciones para mitigar el sobreajuste:
Regularizaci√≥n: Aplicar t√©cnicas de regularizaci√≥n como L2 o dropout.
Aumento de datos (Data Augmentation): Incrementar la variabilidad del conjunto de datos de entrenamiento mediante t√©cnicas de aumento de datos.
Uso de un conjunto de validaci√≥n m√°s grande: Aumentar el tama√±o del conjunto de validaci√≥n para obtener una mejor estimaci√≥n de la capacidad de generalizaci√≥n del modelo.
Early Stopping: Implementar early stopping para detener el entrenamiento cuando la p√©rdida de validaci√≥n ya no mejora.
Estas estrategias pueden ayudar a mejorar la capacidad del modelo para generalizar a datos nuevos y, por ende, mejorar el rendimiento en el conjunto de test.



LISTADO DE ALGORITMOS, FRAMEWORKS Y HERRAMIENTAS PRE ENTRENADAS UTILIZADOS EN EL PROYECTO
El proyecto de detecci√≥n de piletas mediante im√°genes satelitales utiliza varios algoritmos y t√©cnicas para lograr su objetivo. A continuaci√≥n, se presentan algunos de los m√°s relevantes:
Redes Neuronales Convolucionales (CNN):

Estas redes son fundamentales para el aprendizaje profundo en visi√≥n por computadora. Se entrenaron para reconocer patrones y caracter√≠sticas en im√°genes, como formas y texturas. En este proyecto, se utilizan para identificar piscinas en las im√°genes satelitales.


Para mejorar la robustez del modelo, se aplicaron t√©cnicas de argumentaci√≥n de datos, como ......... la rotaci√≥n, el cambio de brillo y la ampliaci√≥n/reducci√≥n de im√°genes.
---


